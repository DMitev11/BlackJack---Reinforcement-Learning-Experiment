{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stable-baselines3 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.3.2)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stable-baselines3) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stable-baselines3) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stable-baselines3) (2.4.1+cu121)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stable-baselines3) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stable-baselines3) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stable-baselines3) (3.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.13->stable-baselines3) (3.16.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.13->stable-baselines3) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.13->stable-baselines3) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from torch>=1.13->stable-baselines3) (74.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->stable-baselines3) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->stable-baselines3) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->stable-baselines3) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->stable-baselines3) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->stable-baselines3) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib->stable-baselines3) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->stable-baselines3) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas->stable-baselines3) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gymnasium[classic-control] in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gymnasium[classic-control]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gymnasium[classic-control]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gymnasium[classic-control]) (2.6.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (1.26.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: jupyter_core in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (5.7.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter_core) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter_core) (306)\n",
      "Requirement already satisfied: traitlets>=5.3 in c:\\users\\dmitev2\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter_core) (5.14.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3\n",
    "!pip install gymnasium[classic-control]\n",
    "!pip install numpy\n",
    "!pip install jupyter_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import gymnasium as gym \n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building an Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import math\n",
    "import random\n",
    "\n",
    "class Card(Enum):\n",
    "    ACE = 11\n",
    "    KING = 10.3\n",
    "    QUEEN = 10.2\n",
    "    JACK = 10.1\n",
    "    TEN = 10.0\n",
    "    NINE = 9\n",
    "    EIGHT = 8\n",
    "    SEVEN = 7\n",
    "    SIX = 6\n",
    "    FIVE = 5\n",
    "    FOUR = 4\n",
    "    THREE = 3\n",
    "    TWO = 2\n",
    "\n",
    "class Action(Enum):\n",
    "    STAY = 0\n",
    "    HIT = 1\n",
    "    DOUBLE_DOWN = 2\n",
    "    SPLIT = 3\n",
    "\n",
    "class Deck():\n",
    "    def __fisherYatesShuffle__(self, values):\n",
    "        for idx, x in enumerate(values):\n",
    "            j = math.floor(random.random() * idx)\n",
    "            cache = x\n",
    "            values[idx] = values[j]\n",
    "            values[j] = cache\n",
    "        return values\n",
    "\n",
    "    def __constructDeck__(self, count):\n",
    "        values = [member.value for member in Card for _ in range(4)] * count\n",
    "        return self.__fisherYatesShuffle__(values)\n",
    "\n",
    "    def __init__(self, count):\n",
    "        self.count = count\n",
    "        self.set = self.__constructDeck__(count)\n",
    "\n",
    "    def drawCard(self):\n",
    "        try:\n",
    "            card = self.set.pop(0)\n",
    "        except IndexError:\n",
    "            self.set = self.__constructDeck__(self.count)\n",
    "            card = self.set.pop(0)\n",
    "\n",
    "        return card\n",
    "\n",
    "# which is the correct condition\n",
    "def calculateSoftHand(values):\n",
    "    cards = [value for value in values if value != -1]\n",
    "    try: idx = cards.index(Card.ACE)\n",
    "    except: idx = -1\n",
    "    mask = (cards != Card.ACE) or (np.arange(len(cards)) == idx)\n",
    "    val = np.sum(np.where(mask, np.floor(cards), 1))\n",
    "    return val\n",
    "\n",
    "def calculateHardHand(values):\n",
    "    cards = [value for value in values if value != -1]\n",
    "    val = np.sum(np.floor(cards))\n",
    "    return val\n",
    "\n",
    "def calculatePairs(values):\n",
    "    cards = np.floor([value for value in values if value != -1])\n",
    "    val = []\n",
    "    for idx, value in enumerate(cards):\n",
    "        if (np.where(cards == value)[0][0] != idx and value not in val):\n",
    "            val = np.append(val, value)\n",
    "\n",
    "    return val\n",
    "\n",
    "def calculateHand(values):\n",
    "    soft = calculateSoftHand(values)\n",
    "    hard = calculateHardHand(values)\n",
    "    pairs = calculatePairs(values)\n",
    "    highValue = soft if hard > 21 else hard\n",
    "\n",
    "    return soft, hard, pairs, highValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackJackPlayEnv(Env):\n",
    "    def __evaluateAction__(self, action):\n",
    "        iter = 0\n",
    "        hand = self.state['player_hands'][self.hand_index]\n",
    "        soft, _, pairs, _ = calculateHand(hand)\n",
    "        len_hand = len([v for v in hand if v != -1])\n",
    "        while True:\n",
    "            if(action - iter <= Action.STAY.value):\n",
    "                self.state['done_hands'][self.hand_index] = 1\n",
    "                return Action.STAY\n",
    "\n",
    "            if(action - iter == Action.HIT.value):\n",
    "                idx = np.where(hand == -1)[0][0]\n",
    "                hand[idx] = self.deck.drawCard()\n",
    "                return Action.HIT\n",
    "\n",
    "            if(action - iter == Action.DOUBLE_DOWN.value and (len_hand == 2 or soft < 11)):\n",
    "                idx = np.where(hand == -1)[0][0]\n",
    "                hand[idx] = self.deck.drawCard()\n",
    "                idx = np.where(hand == -1)[0][0]\n",
    "                hand[idx] = self.deck.drawCard()\n",
    "\n",
    "                return Action.DOUBLE_DOWN\n",
    "\n",
    "            if(action - iter == Action.SPLIT.value and len(pairs) > 0 and len_hand == 2):\n",
    "                card = pairs[0]\n",
    "                #always [0, 1]\n",
    "                indices = np.argwhere(np.floor(hand) == card)\n",
    "                idx = np.max(indices)\n",
    "                hand[idx] = self.deck.drawCard()\n",
    "\n",
    "                first_el = self.state['player_hands'][:, 0]\n",
    "                h_idx = np.where(first_el == -1)[0][0]\n",
    "                self.state['player_hands'][h_idx][0] = card\n",
    "                self.state['player_hands'][h_idx][1] = self.deck.drawCard()\n",
    "\n",
    "                self.state['player_hands_indices'] += 1\n",
    "                self.state['done_hands'][h_idx] = 0\n",
    "                return Action.SPLIT\n",
    "\n",
    "            if((len_hand <= 2 or soft < 11) and len(pairs) > 0):\n",
    "                iter += 4\n",
    "                continue\n",
    "            #action masking\n",
    "            if((len_hand <= 2 or soft < 11) and len(pairs) > 0):\n",
    "                iter += 3\n",
    "                continue\n",
    "            #action masking\n",
    "            iter +=2\n",
    "\n",
    "    def __init__(self):\n",
    "        # Actions we can take - stand, hit, double_down, split,\n",
    "        self.action_space = Discrete(4)\n",
    "        # Observation space: (player_sum, dealer_up_card, usable_ace)\n",
    "        self.observation_space = Dict({\n",
    "            'player_hands': Box(low = -1, high = 11, shape = (6, 21), dtype= np.float32),\n",
    "            'usable_ace': Box(low = -1, high = 1, shape = (6,), dtype= np.int32),\n",
    "            'player_total': Box(low = -1, high = 41, shape = (6,), dtype = np.int32),\n",
    "            'player_hands_indices': Discrete(6),\n",
    "            'done_hands': Box(low = -1, high = 1, shape = (6,), dtype = np.int32),\n",
    "            'dealer_hand': Box(low = -1, high = 11, shape = (21,), dtype= np.float32),\n",
    "            'dealer_total': Discrete(27),\n",
    "        })\n",
    "        self.reset()\n",
    "    \n",
    "    def __nextGame__(self):\n",
    "        player_hands = np.array([[self.deck.drawCard(), self.deck.drawCard()] + 19 * [-1]] + 5 * [21 * [-1]], dtype = np.float32)\n",
    "        dealer_hand = np.array([self.deck.drawCard()] + 20 * [-1], dtype = np.float32)\n",
    "        _, _, _, highValue = calculateHand(player_hands[0])\n",
    "        self.state = {\n",
    "            'player_hands': player_hands,\n",
    "            'usable_ace': np.array([1 if 11 in player_hands else 0] + 5 * [-1], dtype = np.int32),\n",
    "            'player_total': np.array([highValue] + 5 * [-1], dtype= np.int32),\n",
    "            'player_hands_indices': 1,\n",
    "            'done_hands': np.array([0] + 5 * [-1], dtype = np.int32),\n",
    "            'dealer_hand': dealer_hand,\n",
    "            'dealer_total': int(math.floor(dealer_hand[0]))\n",
    "        }\n",
    "        self.hand_index = 0\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "        self.games = 1\n",
    "        self.deck = Deck(4)\n",
    "        self.__nextGame__()\n",
    "        info = {}\n",
    "        return self.state, info\n",
    "\n",
    "    def step(self, action):\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        truncated = False\n",
    "        done = False\n",
    "        reward = 0\n",
    "\n",
    "        ev_action = self.__evaluateAction__(action)\n",
    "        soft, hard, pairs, highValue = calculateHand(self.state['player_hands'][self.hand_index])\n",
    "        self.state['player_total'][self.hand_index] = highValue\n",
    "\n",
    "        if(self.state['done_hands'][self.hand_index] < 1):\n",
    "            if(soft > 21):\n",
    "                self.state['player_hands'][self.hand_index] = 21 * [-1]\n",
    "                self.state['done_hands'][self.hand_index] = -1\n",
    "                self.state['player_hands_indices'] -= 1\n",
    "                reward = -1\n",
    "                self.hand_index -= 1\n",
    "\n",
    "                non_minus_hands = self.state['player_hands'][self.state['player_hands'][:, 0] != -1]\n",
    "                minus_hands = self.state['player_hands'][self.state['player_hands'][:, 0] == -1]\n",
    "                self.state['player_hands'] = np.concatenate((non_minus_hands, minus_hands))\n",
    "\n",
    "                non_minus_done = self.state['done_hands'][self.state['done_hands'] != -1]\n",
    "                minus_done = self.state['done_hands'][self.state['done_hands'] == -1]\n",
    "                self.state['done_hands'] = np.concatenate((non_minus_done, minus_done))\n",
    "\n",
    "                self.hand_index -= 1\n",
    "\n",
    "            elif(soft == 21 or hard == 21):\n",
    "                self.state['player_hands'][self.hand_index] = 21 * [-1]\n",
    "                self.state['done_hands'][self.hand_index] = -1\n",
    "                self.state['player_hands_indices'] -= 1\n",
    "                self.hand_index -= 1\n",
    "                reward = 1\n",
    "\n",
    "                non_minus_hands = self.state['player_hands'][self.state['player_hands'][:, 0] != -1]\n",
    "                minus_hands = self.state['player_hands'][self.state['player_hands'][:, 0] == -1]\n",
    "                self.state['player_hands'] = np.concatenate((non_minus_hands, minus_hands))\n",
    "\n",
    "                non_minus_done = self.state['done_hands'][self.state['done_hands'] != -1]\n",
    "                minus_done = self.state['done_hands'][self.state['done_hands'] == -1]\n",
    "                self.state['done_hands'] = np.concatenate((non_minus_done, minus_done))\n",
    "\n",
    "                self.hand_index -= 1\n",
    "\n",
    "        elif(self.state['done_hands'][self.hand_index] != -1 and ev_action == Action.DOUBLE_DOWN):\n",
    "            self.state['done_hands'][self.hand_index] = 1\n",
    "\n",
    "        self.hand_index = self.hand_index+1 if self.hand_index + 1 < self.state['player_hands_indices'] else 0\n",
    "        #still hand to decide an action\n",
    "        if(np.any(self.state['done_hands'] == 0)):\n",
    "            return self.state, reward, done, truncated, info\n",
    "\n",
    "\n",
    "\n",
    "        #all hands decided upon an action\n",
    "        if(np.any(self.state['done_hands'] == 1)):\n",
    "            _, dealerHard, _, _ = calculateHand(self.state['dealer_hand'])\n",
    "            while(dealerHard < 17):\n",
    "                idx = np.where(self.state['dealer_hand'] == -1)[0][0]\n",
    "                self.state['dealer_hand'][idx] = self.deck.drawCard()\n",
    "                _, dealerHard, _, _ = calculateHand(self.state['dealer_hand'])\n",
    "\n",
    "            if(dealerHard > 21):\n",
    "                reward += len([v for v in self.state['player_hands'] if v[0] != -1])\n",
    "            else:\n",
    "                for idx in range(self.state['player_hands_indices']):\n",
    "                    hand = self.state['player_hands'][idx]\n",
    "                    _, _, _, handHighValue = calculateHand(hand)\n",
    "                    if(handHighValue > dealerHard): reward += 1\n",
    "                    elif(handHighValue == dealerHard): pass\n",
    "                    else: reward += -1\n",
    "\n",
    "            done = True\n",
    "\n",
    "        if(reward > 1):\n",
    "            pass\n",
    "        self.games -= 1\n",
    "        if(self.games <= 0): done = True\n",
    "        else: self.__nextGame__()\n",
    "        return self.state, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "\n",
    "env=BlackJackPlayEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmitev2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\stable_baselines3\\common\\env_checker.py:263: UserWarning: Your observation player_hands has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:1\n",
      "Episode:2 Score:-1\n",
      "Episode:3 Score:-1\n",
      "Episode:4 Score:-1\n",
      "Episode:5 Score:1\n",
      "Episode:6 Score:1\n",
      "Episode:7 Score:1\n",
      "Episode:8 Score:-1\n",
      "Episode:9 Score:1\n",
      "Episode:10 Score:-1\n",
      "Episode:11 Score:-1\n",
      "Episode:12 Score:-1\n",
      "Episode:13 Score:-1\n",
      "Episode:14 Score:-1\n",
      "Episode:15 Score:-1\n",
      "Episode:16 Score:1\n",
      "Episode:17 Score:-1\n",
      "Episode:18 Score:1\n",
      "Episode:19 Score:1\n",
      "Episode:20 Score:0\n",
      "Episode:21 Score:-1\n",
      "Episode:22 Score:-1\n",
      "Episode:23 Score:-1\n",
      "Episode:24 Score:1\n",
      "Episode:25 Score:-1\n",
      "Episode:26 Score:-1\n",
      "Episode:27 Score:-1\n",
      "Episode:28 Score:-1\n",
      "Episode:29 Score:1\n",
      "Episode:30 Score:-1\n",
      "Episode:31 Score:-1\n",
      "Episode:32 Score:-1\n",
      "Episode:33 Score:-1\n",
      "Episode:34 Score:-1\n",
      "Episode:35 Score:1\n",
      "Episode:36 Score:-1\n",
      "Episode:37 Score:0\n",
      "Episode:38 Score:-1\n",
      "Episode:39 Score:-1\n",
      "Episode:40 Score:-1\n",
      "Episode:41 Score:-1\n",
      "Episode:42 Score:0\n",
      "Episode:43 Score:1\n",
      "Episode:44 Score:-1\n",
      "Episode:45 Score:-1\n",
      "Episode:46 Score:-1\n",
      "Episode:47 Score:-1\n",
      "Episode:48 Score:-2\n",
      "Episode:49 Score:-1\n",
      "Episode:50 Score:-2\n",
      "Episode:51 Score:-1\n",
      "Episode:52 Score:-1\n",
      "Episode:53 Score:-1\n",
      "Episode:54 Score:1\n",
      "Episode:55 Score:1\n",
      "Episode:56 Score:-1\n",
      "Episode:57 Score:-1\n",
      "Episode:58 Score:-1\n",
      "Episode:59 Score:-1\n",
      "Episode:60 Score:-1\n",
      "Episode:61 Score:-1\n",
      "Episode:62 Score:0\n",
      "Episode:63 Score:0\n",
      "Episode:64 Score:-1\n",
      "Episode:65 Score:-1\n",
      "Episode:66 Score:0\n",
      "Episode:67 Score:-1\n",
      "Episode:68 Score:-1\n",
      "Episode:69 Score:-1\n",
      "Episode:70 Score:-1\n",
      "Episode:71 Score:-1\n",
      "Episode:72 Score:1\n",
      "Episode:73 Score:-1\n",
      "Episode:74 Score:-1\n",
      "Episode:75 Score:-1\n",
      "Episode:76 Score:-1\n",
      "Episode:77 Score:-1\n",
      "Episode:78 Score:0\n",
      "Episode:79 Score:-2\n",
      "Episode:80 Score:-1\n",
      "Episode:81 Score:-1\n",
      "Episode:82 Score:-1\n",
      "Episode:83 Score:-1\n",
      "Episode:84 Score:-1\n",
      "Episode:85 Score:-1\n",
      "Episode:86 Score:1\n",
      "Episode:87 Score:1\n",
      "Episode:88 Score:1\n",
      "Episode:89 Score:-1\n",
      "Episode:90 Score:-1\n",
      "Episode:91 Score:-1\n",
      "Episode:92 Score:-1\n",
      "Episode:93 Score:1\n",
      "Episode:94 Score:-1\n",
      "Episode:95 Score:1\n",
      "Episode:96 Score:1\n",
      "Episode:97 Score:1\n",
      "Episode:98 Score:-1\n",
      "Episode:99 Score:-2\n",
      "Episode:100 Score:1\n",
      "Episode:101 Score:-1\n",
      "Episode:102 Score:-1\n",
      "Episode:103 Score:0\n",
      "Episode:104 Score:-1\n",
      "Episode:105 Score:1\n",
      "Episode:106 Score:-1\n",
      "Episode:107 Score:-1\n",
      "Episode:108 Score:1\n",
      "Episode:109 Score:-1\n",
      "Episode:110 Score:-1\n",
      "Episode:111 Score:-2\n",
      "Episode:112 Score:1\n",
      "Episode:113 Score:-1\n",
      "Episode:114 Score:-1\n",
      "Episode:115 Score:-1\n",
      "Episode:116 Score:-1\n",
      "Episode:117 Score:-1\n",
      "Episode:118 Score:-1\n",
      "Episode:119 Score:-1\n",
      "Episode:120 Score:1\n",
      "Episode:121 Score:-1\n",
      "Episode:122 Score:-1\n",
      "Episode:123 Score:-1\n",
      "Episode:124 Score:1\n",
      "Episode:125 Score:-1\n",
      "Episode:126 Score:-1\n",
      "Episode:127 Score:1\n",
      "Episode:128 Score:0\n",
      "Episode:129 Score:-1\n",
      "Episode:130 Score:1\n",
      "Episode:131 Score:0\n",
      "Episode:132 Score:1\n",
      "Episode:133 Score:-1\n",
      "Episode:134 Score:-1\n",
      "Episode:135 Score:-1\n",
      "Episode:136 Score:1\n",
      "Episode:137 Score:-1\n",
      "Episode:138 Score:-1\n",
      "Episode:139 Score:-1\n",
      "Episode:140 Score:-1\n",
      "Episode:141 Score:-1\n",
      "Episode:142 Score:-1\n",
      "Episode:143 Score:-1\n",
      "Episode:144 Score:-1\n",
      "Episode:145 Score:1\n",
      "Episode:146 Score:-1\n",
      "Episode:147 Score:-1\n",
      "Episode:148 Score:-1\n",
      "Episode:149 Score:-1\n",
      "Episode:150 Score:-1\n",
      "Episode:151 Score:-1\n",
      "Episode:152 Score:1\n",
      "Episode:153 Score:-1\n",
      "Episode:154 Score:-1\n",
      "Episode:155 Score:1\n",
      "Episode:156 Score:-1\n",
      "Episode:157 Score:-1\n",
      "Episode:158 Score:1\n",
      "Episode:159 Score:-1\n",
      "Episode:160 Score:-1\n",
      "Episode:161 Score:-1\n",
      "Episode:162 Score:-1\n",
      "Episode:163 Score:-1\n",
      "Episode:164 Score:-1\n",
      "Episode:165 Score:1\n",
      "Episode:166 Score:1\n",
      "Episode:167 Score:1\n",
      "Episode:168 Score:0\n",
      "Episode:169 Score:1\n",
      "Episode:170 Score:-1\n",
      "Episode:171 Score:-1\n",
      "Episode:172 Score:1\n",
      "Episode:173 Score:-1\n",
      "Episode:174 Score:-1\n",
      "Episode:175 Score:1\n",
      "Episode:176 Score:-1\n",
      "Episode:177 Score:-1\n",
      "Episode:178 Score:-1\n",
      "Episode:179 Score:-1\n",
      "Episode:180 Score:-1\n",
      "Episode:181 Score:1\n",
      "Episode:182 Score:1\n",
      "Episode:183 Score:-1\n",
      "Episode:184 Score:-1\n",
      "Episode:185 Score:1\n",
      "Episode:186 Score:-1\n",
      "Episode:187 Score:-1\n",
      "Episode:188 Score:-1\n",
      "Episode:189 Score:-1\n",
      "Episode:190 Score:1\n",
      "Episode:191 Score:1\n",
      "Episode:192 Score:-1\n",
      "Episode:193 Score:-1\n",
      "Episode:194 Score:-1\n",
      "Episode:195 Score:-1\n",
      "Episode:196 Score:-1\n",
      "Episode:197 Score:-1\n",
      "Episode:198 Score:-1\n",
      "Episode:199 Score:1\n",
      "Episode:200 Score:-1\n",
      "Episode:201 Score:0\n",
      "Episode:202 Score:-1\n",
      "Episode:203 Score:-1\n",
      "Episode:204 Score:-1\n",
      "Episode:205 Score:-1\n",
      "Episode:206 Score:1\n",
      "Episode:207 Score:-1\n",
      "Episode:208 Score:-1\n",
      "Episode:209 Score:-1\n",
      "Episode:210 Score:-1\n",
      "Episode:211 Score:-1\n",
      "Episode:212 Score:-1\n",
      "Episode:213 Score:-1\n",
      "Episode:214 Score:1\n",
      "Episode:215 Score:-1\n",
      "Episode:216 Score:-1\n",
      "Episode:217 Score:-1\n",
      "Episode:218 Score:1\n",
      "Episode:219 Score:-1\n",
      "Episode:220 Score:-1\n",
      "Episode:221 Score:-1\n",
      "Episode:222 Score:-1\n",
      "Episode:223 Score:0\n",
      "Episode:224 Score:-1\n",
      "Episode:225 Score:-1\n",
      "Episode:226 Score:-1\n",
      "Episode:227 Score:-1\n",
      "Episode:228 Score:1\n",
      "Episode:229 Score:-1\n",
      "Episode:230 Score:-1\n",
      "Episode:231 Score:1\n",
      "Episode:232 Score:1\n",
      "Episode:233 Score:-1\n",
      "Episode:234 Score:-1\n",
      "Episode:235 Score:-1\n",
      "Episode:236 Score:-1\n",
      "Episode:237 Score:1\n",
      "Episode:238 Score:-1\n",
      "Episode:239 Score:1\n",
      "Episode:240 Score:-1\n",
      "Episode:241 Score:-1\n",
      "Episode:242 Score:-3\n",
      "Episode:243 Score:-1\n",
      "Episode:244 Score:-1\n",
      "Episode:245 Score:-1\n",
      "Episode:246 Score:-1\n",
      "Episode:247 Score:-1\n",
      "Episode:248 Score:1\n",
      "Episode:249 Score:-1\n",
      "Episode:250 Score:-1\n",
      "Episode:251 Score:-1\n",
      "Episode:252 Score:-1\n",
      "Episode:253 Score:-1\n",
      "Episode:254 Score:-1\n",
      "Episode:255 Score:-1\n",
      "Episode:256 Score:1\n",
      "Episode:257 Score:-1\n",
      "Episode:258 Score:1\n",
      "Episode:259 Score:-1\n",
      "Episode:260 Score:-1\n",
      "Episode:261 Score:1\n",
      "Episode:262 Score:1\n",
      "Episode:263 Score:-1\n",
      "Episode:264 Score:-1\n",
      "Episode:265 Score:1\n",
      "Episode:266 Score:-1\n",
      "Episode:267 Score:-1\n",
      "Episode:268 Score:-1\n",
      "Episode:269 Score:1\n",
      "Episode:270 Score:-1\n",
      "Episode:271 Score:1\n",
      "Episode:272 Score:-1\n",
      "Episode:273 Score:-1\n",
      "Episode:274 Score:-1\n",
      "Episode:275 Score:-1\n",
      "Episode:276 Score:-1\n",
      "Episode:277 Score:-1\n",
      "Episode:278 Score:1\n",
      "Episode:279 Score:0\n",
      "Episode:280 Score:1\n",
      "Episode:281 Score:1\n",
      "Episode:282 Score:-1\n",
      "Episode:283 Score:-1\n",
      "Episode:284 Score:-1\n",
      "Episode:285 Score:1\n",
      "Episode:286 Score:-1\n",
      "Episode:287 Score:-1\n",
      "Episode:288 Score:-1\n",
      "Episode:289 Score:1\n",
      "Episode:290 Score:-1\n",
      "Episode:291 Score:-1\n",
      "Episode:292 Score:-1\n",
      "Episode:293 Score:-2\n",
      "Episode:294 Score:-1\n",
      "Episode:295 Score:-1\n",
      "Episode:296 Score:1\n",
      "Episode:297 Score:-2\n",
      "Episode:298 Score:-1\n",
      "Episode:299 Score:-1\n",
      "Episode:300 Score:-1\n",
      "Episode:301 Score:-1\n",
      "Episode:302 Score:-1\n",
      "Episode:303 Score:-1\n",
      "Episode:304 Score:-1\n",
      "Episode:305 Score:-1\n",
      "Episode:306 Score:1\n",
      "Episode:307 Score:-1\n",
      "Episode:308 Score:-1\n",
      "Episode:309 Score:-1\n",
      "Episode:310 Score:-1\n",
      "Episode:311 Score:-1\n",
      "Episode:312 Score:1\n",
      "Episode:313 Score:-1\n",
      "Episode:314 Score:1\n",
      "Episode:315 Score:-1\n",
      "Episode:316 Score:-1\n",
      "Episode:317 Score:-1\n",
      "Episode:318 Score:-1\n",
      "Episode:319 Score:-1\n",
      "Episode:320 Score:1\n",
      "Episode:321 Score:-1\n",
      "Episode:322 Score:0\n",
      "Episode:323 Score:-1\n",
      "Episode:324 Score:-1\n",
      "Episode:325 Score:-1\n",
      "Episode:326 Score:-1\n",
      "Episode:327 Score:-1\n",
      "Episode:328 Score:1\n",
      "Episode:329 Score:-1\n",
      "Episode:330 Score:0\n",
      "Episode:331 Score:1\n",
      "Episode:332 Score:-1\n",
      "Episode:333 Score:-1\n",
      "Episode:334 Score:-1\n",
      "Episode:335 Score:1\n",
      "Episode:336 Score:1\n",
      "Episode:337 Score:-1\n",
      "Episode:338 Score:-1\n",
      "Episode:339 Score:1\n",
      "Episode:340 Score:-1\n",
      "Episode:341 Score:-1\n",
      "Episode:342 Score:-1\n",
      "Episode:343 Score:-1\n",
      "Episode:344 Score:-1\n",
      "Episode:345 Score:-1\n",
      "Episode:346 Score:-1\n",
      "Episode:347 Score:-1\n",
      "Episode:348 Score:-1\n",
      "Episode:349 Score:-1\n",
      "Episode:350 Score:-1\n",
      "Episode:351 Score:-1\n",
      "Episode:352 Score:-1\n",
      "Episode:353 Score:-1\n",
      "Episode:354 Score:1\n",
      "Episode:355 Score:-1\n",
      "Episode:356 Score:1\n",
      "Episode:357 Score:-1\n",
      "Episode:358 Score:1\n",
      "Episode:359 Score:1\n",
      "Episode:360 Score:-1\n",
      "Episode:361 Score:-1\n",
      "Episode:362 Score:-1\n",
      "Episode:363 Score:-1\n",
      "Episode:364 Score:-1\n",
      "Episode:365 Score:-1\n",
      "Episode:366 Score:-1\n",
      "Episode:367 Score:-1\n",
      "Episode:368 Score:-1\n",
      "Episode:369 Score:1\n",
      "Episode:370 Score:-1\n",
      "Episode:371 Score:1\n",
      "Episode:372 Score:-1\n",
      "Episode:373 Score:-1\n",
      "Episode:374 Score:-1\n",
      "Episode:375 Score:0\n",
      "Episode:376 Score:-1\n",
      "Episode:377 Score:-1\n",
      "Episode:378 Score:-1\n",
      "Episode:379 Score:-1\n",
      "Episode:380 Score:-1\n",
      "Episode:381 Score:-1\n",
      "Episode:382 Score:-2\n",
      "Episode:383 Score:-1\n",
      "Episode:384 Score:-1\n",
      "Episode:385 Score:-1\n",
      "Episode:386 Score:-1\n",
      "Episode:387 Score:-1\n",
      "Episode:388 Score:1\n",
      "Episode:389 Score:1\n",
      "Episode:390 Score:-1\n",
      "Episode:391 Score:-1\n",
      "Episode:392 Score:-1\n",
      "Episode:393 Score:1\n",
      "Episode:394 Score:1\n",
      "Episode:395 Score:-1\n",
      "Episode:396 Score:-1\n",
      "Episode:397 Score:-1\n",
      "Episode:398 Score:-1\n",
      "Episode:399 Score:-1\n",
      "Episode:400 Score:-1\n",
      "Episode:401 Score:-1\n",
      "Episode:402 Score:-1\n",
      "Episode:403 Score:0\n",
      "Episode:404 Score:-1\n",
      "Episode:405 Score:-1\n",
      "Episode:406 Score:-1\n",
      "Episode:407 Score:1\n",
      "Episode:408 Score:-1\n",
      "Episode:409 Score:-1\n",
      "Episode:410 Score:1\n",
      "Episode:411 Score:1\n",
      "Episode:412 Score:1\n",
      "Episode:413 Score:-1\n",
      "Episode:414 Score:1\n",
      "Episode:415 Score:-1\n",
      "Episode:416 Score:-1\n",
      "Episode:417 Score:1\n",
      "Episode:418 Score:-1\n",
      "Episode:419 Score:-1\n",
      "Episode:420 Score:-1\n",
      "Episode:421 Score:1\n",
      "Episode:422 Score:1\n",
      "Episode:423 Score:-1\n",
      "Episode:424 Score:-1\n",
      "Episode:425 Score:1\n",
      "Episode:426 Score:-1\n",
      "Episode:427 Score:-1\n",
      "Episode:428 Score:-1\n",
      "Episode:429 Score:1\n",
      "Episode:430 Score:-1\n",
      "Episode:431 Score:-1\n",
      "Episode:432 Score:-1\n",
      "Episode:433 Score:-1\n",
      "Episode:434 Score:-1\n",
      "Episode:435 Score:1\n",
      "Episode:436 Score:1\n",
      "Episode:437 Score:-1\n",
      "Episode:438 Score:-1\n",
      "Episode:439 Score:1\n",
      "Episode:440 Score:-1\n",
      "Episode:441 Score:-1\n",
      "Episode:442 Score:-1\n",
      "Episode:443 Score:-1\n",
      "Episode:444 Score:1\n",
      "Episode:445 Score:0\n",
      "Episode:446 Score:1\n",
      "Episode:447 Score:-1\n",
      "Episode:448 Score:1\n",
      "Episode:449 Score:-1\n",
      "Episode:450 Score:-1\n",
      "Episode:451 Score:-1\n",
      "Episode:452 Score:-1\n",
      "Episode:453 Score:1\n",
      "Episode:454 Score:-1\n",
      "Episode:455 Score:-1\n",
      "Episode:456 Score:-1\n",
      "Episode:457 Score:-1\n",
      "Episode:458 Score:-1\n",
      "Episode:459 Score:-1\n",
      "Episode:460 Score:-1\n",
      "Episode:461 Score:-1\n",
      "Episode:462 Score:-1\n",
      "Episode:463 Score:-1\n",
      "Episode:464 Score:-1\n",
      "Episode:465 Score:-1\n",
      "Episode:466 Score:-1\n",
      "Episode:467 Score:-1\n",
      "Episode:468 Score:-1\n",
      "Episode:469 Score:-1\n",
      "Episode:470 Score:-1\n",
      "Episode:471 Score:-1\n",
      "Episode:472 Score:1\n",
      "Episode:473 Score:-1\n",
      "Episode:474 Score:0\n",
      "Episode:475 Score:-1\n",
      "Episode:476 Score:-1\n",
      "Episode:477 Score:-1\n",
      "Episode:478 Score:-1\n",
      "Episode:479 Score:-1\n",
      "Episode:480 Score:-1\n",
      "Episode:481 Score:-1\n",
      "Episode:482 Score:-1\n",
      "Episode:483 Score:-1\n",
      "Episode:484 Score:-1\n",
      "Episode:485 Score:0\n",
      "Episode:486 Score:-1\n",
      "Episode:487 Score:-1\n",
      "Episode:488 Score:-1\n",
      "Episode:489 Score:0\n",
      "Episode:490 Score:-1\n",
      "Episode:491 Score:1\n",
      "Episode:492 Score:-1\n",
      "Episode:493 Score:1\n",
      "Episode:494 Score:-1\n",
      "Episode:495 Score:-1\n",
      "Episode:496 Score:1\n",
      "Episode:497 Score:-1\n",
      "Episode:498 Score:-1\n",
      "Episode:499 Score:-1\n",
      "Episode:500 Score:1\n"
     ]
    }
   ],
   "source": [
    "episodes = 500\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset(0)\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, truncated, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model_path = os.path.join('./Cards_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "#model = PPO(\"MultiInputPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(model_path, env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.41     |\n",
      "|    ep_rew_mean     | -0.61    |\n",
      "| time/              |          |\n",
      "|    fps             | 296      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.35       |\n",
      "|    ep_rew_mean          | -0.59      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 275        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 14         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01965183 |\n",
      "|    clip_fraction        | 0.316      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | -0.0298    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.241      |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0492    |\n",
      "|    value_loss           | 0.722      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.32       |\n",
      "|    ep_rew_mean          | -0.45      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 270        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02163284 |\n",
      "|    clip_fraction        | 0.379      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.00881    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.329      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0571    |\n",
      "|    value_loss           | 0.856      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.39       |\n",
      "|    ep_rew_mean          | -0.38      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01930327 |\n",
      "|    clip_fraction        | 0.39       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.0527     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.332      |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -0.056     |\n",
      "|    value_loss           | 0.873      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.22       |\n",
      "|    ep_rew_mean          | -0.22      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 261        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01859301 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.0224     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.379      |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.042     |\n",
      "|    value_loss           | 0.855      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31        |\n",
      "|    ep_rew_mean          | -0.31       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025335003 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.076       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.382       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0289     |\n",
      "|    value_loss           | 0.836       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37        |\n",
      "|    ep_rew_mean          | -0.19       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 233         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010798845 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.915      |\n",
      "|    explained_variance   | 0.0986      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.369       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.829       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26        |\n",
      "|    ep_rew_mean          | -0.06       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 226         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009787943 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.144       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.367       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.819       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2         |\n",
      "|    ep_rew_mean          | 0.03        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009137398 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.82       |\n",
      "|    explained_variance   | 0.172       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.761       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.35         |\n",
      "|    ep_rew_mean          | -0.05        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 217          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065914667 |\n",
      "|    clip_fraction        | 0.093        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.761       |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.448        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 0.774        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31        |\n",
      "|    ep_rew_mean          | -0.22       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 213         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008207886 |\n",
      "|    clip_fraction        | 0.0901      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.681      |\n",
      "|    explained_variance   | 0.0965      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.425       |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    value_loss           | 0.792       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.29       |\n",
      "|    ep_rew_mean          | -0.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 210        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 116        |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00962011 |\n",
      "|    clip_fraction        | 0.0988     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.638     |\n",
      "|    explained_variance   | 0.179      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.305      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.00652   |\n",
      "|    value_loss           | 0.728      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23        |\n",
      "|    ep_rew_mean          | -0.08       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008355973 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.562      |\n",
      "|    explained_variance   | 0.168       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.361       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    value_loss           | 0.749       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.32       |\n",
      "|    ep_rew_mean          | -0.19      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 205        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 139        |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00518914 |\n",
      "|    clip_fraction        | 0.0712     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.533     |\n",
      "|    explained_variance   | 0.164      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.424      |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0034    |\n",
      "|    value_loss           | 0.747      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21        |\n",
      "|    ep_rew_mean          | -0.05       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010329124 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    value_loss           | 0.76        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.23         |\n",
      "|    ep_rew_mean          | 0.04         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083366595 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.354        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    value_loss           | 0.764        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25        |\n",
      "|    ep_rew_mean          | -0.09       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 197         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005860009 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.451      |\n",
      "|    explained_variance   | 0.109       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.408       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    value_loss           | 0.798       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27         |\n",
      "|    ep_rew_mean          | -0.09        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 195          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056582727 |\n",
      "|    clip_fraction        | 0.0634       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.162        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.272        |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    value_loss           | 0.769        |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59.4, 0.9165151389911681)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
