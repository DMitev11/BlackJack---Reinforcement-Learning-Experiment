{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3\n",
    "!pip install gymnasium[classic-control]\n",
    "!pip install numpy\n",
    "!pip install jupyter_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box, Dict\n",
    "\n",
    "from stable_baselines3 import PPO, DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Building an Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import math\n",
    "import random\n",
    "\n",
    "class Card(Enum):\n",
    "    ACE = 11\n",
    "    KING = 10.3\n",
    "    QUEEN = 10.2\n",
    "    JACK = 10.1\n",
    "    TEN = 10.0\n",
    "    NINE = 9\n",
    "    EIGHT = 8\n",
    "    SEVEN = 7\n",
    "    SIX = 6\n",
    "    FIVE = 5\n",
    "    FOUR = 4\n",
    "    THREE = 3\n",
    "    TWO = 2\n",
    "\n",
    "class Action(Enum):\n",
    "    STAY = 0\n",
    "    HIT = 1\n",
    "    DOUBLE_DOWN = 2\n",
    "    SPLIT = 3\n",
    "\n",
    "class Deck():\n",
    "    def __fisherYatesShuffle__(self, values):\n",
    "        for idx, x in enumerate(values):\n",
    "            j = math.floor(random.random() * idx)\n",
    "            cache = x\n",
    "            values[idx] = values[j]\n",
    "            values[j] = cache\n",
    "        return values\n",
    "\n",
    "    def __constructDeck__(self, count):\n",
    "        values = [member.value for member in Card for _ in range(4)] * count\n",
    "        return self.__fisherYatesShuffle__(values)\n",
    "\n",
    "    def __init__(self, count):\n",
    "        self.count = count\n",
    "        self.set = self.__constructDeck__(count)\n",
    "\n",
    "    def drawCard(self):\n",
    "        try:\n",
    "            card = self.set.pop(0)\n",
    "        except IndexError:\n",
    "            self.set = self.__constructDeck__(self.count)\n",
    "            card = self.set.pop(0)\n",
    "\n",
    "        return card\n",
    "\n",
    "# which is the correct condition\n",
    "def calculateSoftHand(values):\n",
    "    cards = [value for value in values if value != -1]\n",
    "    try: idx = cards.index(Card.ACE)\n",
    "    except: idx = -1\n",
    "    mask = (cards != Card.ACE) or (np.arange(len(cards)) == idx)\n",
    "    val = np.sum(np.where(mask, np.floor(cards), 1))\n",
    "    return val\n",
    "\n",
    "def calculateHardHand(values):\n",
    "    cards = [value for value in values if value != -1]\n",
    "    val = np.sum(np.floor(cards))\n",
    "    return val\n",
    "\n",
    "def calculatePairs(values):\n",
    "    cards = np.floor([value for value in values if value != -1])\n",
    "    val = []\n",
    "    for idx, value in enumerate(cards):\n",
    "        if (np.where(cards == value)[0][0] != idx and value not in val):\n",
    "            val = np.append(val, value)\n",
    "\n",
    "    return val\n",
    "\n",
    "def calculateHand(values):\n",
    "    soft = calculateSoftHand(values)\n",
    "    hard = calculateHardHand(values)\n",
    "    pairs = calculatePairs(values)\n",
    "    highValue = soft if hard > 21 else hard\n",
    "\n",
    "    return soft, hard, pairs, highValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackJackPlayEnv(Env):\n",
    "    def __evaluateAction__(self, action):\n",
    "        iter = 0\n",
    "        hand = self.state['player_hands'][self.hand_index]\n",
    "        soft, _, pairs, _ = calculateHand(hand)\n",
    "        len_hand = len([v for v in hand if v != -1])\n",
    "        while True:\n",
    "            if(action - iter <= Action.STAY.value):\n",
    "                self.state['done_hands'][self.hand_index] = 1\n",
    "                return Action.STAY\n",
    "\n",
    "            if(action - iter == Action.HIT.value):\n",
    "                idx = np.where(hand == -1)[0][0]\n",
    "                hand[idx] = self.deck.drawCard()\n",
    "                return Action.HIT\n",
    "\n",
    "            if(action - iter == Action.DOUBLE_DOWN.value and (len_hand == 2 or soft < 11)):\n",
    "                idx = np.where(hand == -1)[0][0]\n",
    "                hand[idx] = self.deck.drawCard()\n",
    "                idx = np.where(hand == -1)[0][0]\n",
    "                hand[idx] = self.deck.drawCard()\n",
    "\n",
    "                return Action.DOUBLE_DOWN\n",
    "\n",
    "            if(action - iter == Action.SPLIT.value and len(pairs) > 0 and len_hand == 2):\n",
    "                card = pairs[0]\n",
    "                #always [0, 1]\n",
    "                indices = np.argwhere(np.floor(hand) == card)\n",
    "                idx = np.max(indices)\n",
    "                hand[idx] = self.deck.drawCard()\n",
    "\n",
    "                first_el = self.state['player_hands'][:, 0]\n",
    "                h_idx = np.where(first_el == -1)[0][0]\n",
    "                self.state['player_hands'][h_idx][0] = card\n",
    "                self.state['player_hands'][h_idx][1] = self.deck.drawCard()\n",
    "\n",
    "                self.state['player_hands_indices'] += 1\n",
    "                self.state['done_hands'][h_idx] = 0\n",
    "                return Action.SPLIT\n",
    "\n",
    "            if((len_hand <= 2 or soft < 11) and len(pairs) > 0):\n",
    "                iter += 4\n",
    "                continue\n",
    "            #action masking\n",
    "            if((len_hand <= 2 or soft < 11) and len(pairs) > 0):\n",
    "                iter += 3\n",
    "                continue\n",
    "            #action masking\n",
    "            iter +=2\n",
    "\n",
    "    def __init__(self):\n",
    "        # Actions we can take - stand, hit, double_down, split,\n",
    "        self.action_space = Discrete(4)\n",
    "        # Observation space: (player_sum, dealer_up_card, usable_ace)\n",
    "        self.observation_space = Dict({\n",
    "            'player_hands': Box(low = -1, high = 11, shape = (6, 21), dtype= np.float32),\n",
    "            'usable_ace': Box(low = -1, high = 1, shape = (6,), dtype= np.int32),\n",
    "            'player_total': Box(low = -1, high = 41, shape = (6,), dtype = np.int32),\n",
    "            'player_hands_indices': Discrete(6),\n",
    "            'done_hands': Box(low = -1, high = 1, shape = (6,), dtype = np.int32),\n",
    "            'dealer_hand': Box(low = -1, high = 11, shape = (21,), dtype= np.float32),\n",
    "            'dealer_total': Discrete(27),\n",
    "        })\n",
    "        self.reset()\n",
    "    \n",
    "    def __nextGame__(self):\n",
    "        player_hands = np.array([[self.deck.drawCard(), self.deck.drawCard()] + 19 * [-1]] + 5 * [21 * [-1]], dtype = np.float32)\n",
    "        dealer_hand = np.array([self.deck.drawCard()] + 20 * [-1], dtype = np.float32)\n",
    "        _, _, _, highValue = calculateHand(player_hands[0])\n",
    "        self.state = {\n",
    "            'player_hands': player_hands,\n",
    "            'usable_ace': np.array([1 if 11 in player_hands else 0] + 5 * [-1], dtype = np.int32),\n",
    "            'player_total': np.array([highValue] + 5 * [-1], dtype= np.int32),\n",
    "            'player_hands_indices': 1,\n",
    "            'done_hands': np.array([0] + 5 * [-1], dtype = np.int32),\n",
    "            'dealer_hand': dealer_hand,\n",
    "            'dealer_total': int(math.floor(dealer_hand[0]))\n",
    "        }\n",
    "        self.hand_index = 0\n",
    "\n",
    "    def reset(self, seed=0):\n",
    "        self.games = 1\n",
    "        self.deck = Deck(4)\n",
    "        self.__nextGame__()\n",
    "        info = {}\n",
    "        return self.state, info\n",
    "\n",
    "    def step(self, action):\n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        truncated = False\n",
    "        done = False\n",
    "        reward = 0\n",
    "\n",
    "        ev_action = self.__evaluateAction__(action)\n",
    "        soft, hard, pairs, highValue = calculateHand(self.state['player_hands'][self.hand_index])\n",
    "        self.state['player_total'][self.hand_index] = highValue\n",
    "\n",
    "        if(self.state['done_hands'][self.hand_index] < 1):\n",
    "            if(soft > 21):\n",
    "                self.state['player_hands'][self.hand_index] = 21 * [-1]\n",
    "                self.state['done_hands'][self.hand_index] = -1\n",
    "                self.state['player_hands_indices'] -= 1\n",
    "                reward = -1\n",
    "                self.hand_index -= 1\n",
    "\n",
    "                non_minus_hands = self.state['player_hands'][self.state['player_hands'][:, 0] != -1]\n",
    "                minus_hands = self.state['player_hands'][self.state['player_hands'][:, 0] == -1]\n",
    "                self.state['player_hands'] = np.concatenate((non_minus_hands, minus_hands))\n",
    "\n",
    "                non_minus_done = self.state['done_hands'][self.state['done_hands'] != -1]\n",
    "                minus_done = self.state['done_hands'][self.state['done_hands'] == -1]\n",
    "                self.state['done_hands'] = np.concatenate((non_minus_done, minus_done))\n",
    "\n",
    "                self.hand_index -= 1\n",
    "\n",
    "            elif(soft == 21 or hard == 21):\n",
    "                self.state['player_hands'][self.hand_index] = 21 * [-1]\n",
    "                self.state['done_hands'][self.hand_index] = -1\n",
    "                self.state['player_hands_indices'] -= 1\n",
    "                self.hand_index -= 1\n",
    "                reward = 1\n",
    "\n",
    "                non_minus_hands = self.state['player_hands'][self.state['player_hands'][:, 0] != -1]\n",
    "                minus_hands = self.state['player_hands'][self.state['player_hands'][:, 0] == -1]\n",
    "                self.state['player_hands'] = np.concatenate((non_minus_hands, minus_hands))\n",
    "\n",
    "                non_minus_done = self.state['done_hands'][self.state['done_hands'] != -1]\n",
    "                minus_done = self.state['done_hands'][self.state['done_hands'] == -1]\n",
    "                self.state['done_hands'] = np.concatenate((non_minus_done, minus_done))\n",
    "\n",
    "                self.hand_index -= 1\n",
    "\n",
    "        elif(self.state['done_hands'][self.hand_index] != -1 and ev_action == Action.DOUBLE_DOWN):\n",
    "            self.state['done_hands'][self.hand_index] = 1\n",
    "\n",
    "        self.hand_index = self.hand_index+1 if self.hand_index + 1 < self.state['player_hands_indices'] else 0\n",
    "        #still hand to decide an action\n",
    "        if(np.any(self.state['done_hands'] == 0)):\n",
    "            return self.state, reward, done, truncated, info\n",
    "\n",
    "\n",
    "\n",
    "        #all hands decided upon an action\n",
    "        if(np.any(self.state['done_hands'] == 1)):\n",
    "            _, dealerHard, _, _ = calculateHand(self.state['dealer_hand'])\n",
    "            while(dealerHard < 17):\n",
    "                idx = np.where(self.state['dealer_hand'] == -1)[0][0]\n",
    "                self.state['dealer_hand'][idx] = self.deck.drawCard()\n",
    "                _, dealerHard, _, _ = calculateHand(self.state['dealer_hand'])\n",
    "\n",
    "            if(dealerHard > 21):\n",
    "                reward += len([v for v in self.state['player_hands'] if v[0] != -1])\n",
    "            else:\n",
    "                for idx in range(self.state['player_hands_indices']):\n",
    "                    hand = self.state['player_hands'][idx]\n",
    "                    _, _, _, handHighValue = calculateHand(hand)\n",
    "                    if(handHighValue > dealerHard): reward += 1\n",
    "                    elif(handHighValue == dealerHard): pass\n",
    "                    else: reward += -1\n",
    "\n",
    "            done = True\n",
    "\n",
    "        if(reward > 1):\n",
    "            pass\n",
    "        self.games -= 1\n",
    "        if(self.games <= 0): done = True\n",
    "        else: self.__nextGame__()\n",
    "        return self.state, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "\n",
    "env=BlackJackPlayEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 500\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset(0)\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, truncated, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model_path = os.path.join('./Cards_PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = PPO(\"MultiInputPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(model_path, env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=400000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=1000, deterministic=False, return_episode_rewards=True, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
